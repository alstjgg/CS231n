{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 3 - Loss Functions & Optimization\n",
    "***\n",
    "# Linear Classification\n",
    "A **Linear classificatier** tries to find a lind that best seperates classes. They are the building blocks of Neural Networks, as they can be combined like lego blocks to construct a complex neural network.\n",
    "\n",
    "![image.png](https://discriminantanalysis.readthedocs.io/en/latest/_images/lda.png)\n",
    "\n",
    "Unlike KNN, where the whole training dataset is memorized and used in prediction, a linear classifier is a **parametric model**, which, after training, summarizes the training set into a set of parameters. Only this parameter set is later needed for prediction, therefore allowing efficient prediction(in terms of both space and time) of new data.\n",
    "\n",
    "### Limitation\n",
    "#### Single Template\n",
    "The linear classification model for images creates a single template for each class.\n",
    "However, images of the same class can be very different. A single template cannot capture the variance between such images.\n",
    "\n",
    "#### Nonlinear Classification\n",
    "Linear classification has a hard time classifying nonlinear classes.\n",
    "\n",
    "\n",
    "### Components\n",
    "We create 2 major components in this approach. A **score function** maps raw input data to class scores, while a **loss function** quantifies the accuracy of predictions. With these components, we construct an **optimization problem** in which we minimize the loss function with respect to the parameter set of the score function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Score Function\n",
    "A **score function** maps the pixel values of an image to confidence scores for each class. The linear classifier uses a linear score function to measure the possibilty of an image having a label.\n",
    "\n",
    "$$f(x_i, W, b) = W\\cdot x_i + b$$\n",
    "\n",
    "- $f$ is the score function.\n",
    "- $x_i$ is the input data, in which all pixel values of the input image are flattened out to a single column vector\n",
    "- $W$ is the parameter set, also called *weights*.\n",
    "- $b$ is a data-independent bias vectpr which scales each class.\n",
    "\n",
    "As we can see, $W$ and $b$ is controllable by the user, and is the only thing needed for future prediction. Thus it is crucial to find to optimal $W$ and $b$ for a classifier.\n",
    "\n",
    "#### Visual Example\n",
    "\n",
    "![image.png](http://cs231n.github.io/assets/imagemap.jpg)\n",
    "\n",
    "Each value of $f(x_i, W, b)$ is the score of the $i^{th}$ input image being in each class. A higher score means a higher likelihood for the image being in that class *(the cat score is the highest)*. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function\n",
    "A **loss function** measures how good(or bad) your classifier is, given **a dataset** that includes **input images ($x_i$)** with their **correct labels ($y_i$)** and **a model** that tries to classify input images into correct classes.\n",
    "\n",
    "$$L = {1 \\over N} {\\sum_i}L_i(f(x_i, W, b), y_i)$$\n",
    "\n",
    "- $L$ is the average of all loss over the dataset\n",
    "- $N$ is the number of images in the dataset\n",
    "- $L_i$ is the loss of the $i^{th}$ image\n",
    "- $f(x_i, W, b)$ is the predicted label of the image (*integer*), often notated as $s$\n",
    "- $y_i$ is the true label of the image (*integer*)\n",
    "\n",
    "## Hinge Loss (Multi-class SVM Loss)\n",
    "A **multi-class SVM** is the generalization of the binary SVM.\n",
    "\n",
    "$$L_i = \\sum_{j \\neq y_i} {max(0, s_j - s_{y_i} + 1)}$$\n",
    "\n",
    "- $0 \\leq L_i \\leq 1$\n",
    "- $j \\neq y_i$ indicates that the loss function is computed on every class except the true label\n",
    "- $s_j$ is the score of the incorrect class $j$\n",
    "- $s_{y_i}$ is the score of the correct class\n",
    "- $1$ is the safety margin, whose value is arbitrary\n",
    "\n",
    "This assigns $0$ to $L_i$ if $s_{y_i} > s_j + 1$, that is, if the score of the true class is higher than the score of class $j$ with a safety margin of $1$.\n",
    "\n",
    "![image.png](https://i.stack.imgur.com/Ifeze.png)\n",
    "\n",
    "The $x$ axis in this graph is $s_{y_i}$ while the $y$ axis is the value of the loss function.\n",
    "\n",
    "As $s_{y_i}$ increases (the model selects the correct class), the value of loss decreases linearly until it exceeds the safety margin. Then it continues to be 0, as the model has settled down on the correct class.\n",
    "\n",
    "As we can observe, this loss functions tries to make the score of the true class higher until it reaches a certain threshold. After that, the model no longer updates as it has found the answer.\n",
    "\n",
    "#### Some observations\n",
    "1. Even if the input data changes a bit, the result doesn't really change because of the safety margin. The model has already decided on its prediction\n",
    "2. If $s \\approx 0$ for all classes, $L_i \\approx NumOfClasses - 1$, because every $L_i$ approximates to 1\n",
    "3. If a certain parameter set $W$ minimizes the total loss of the model, than there exists another set that also optimizes. In other words, set $W$ is not unique. To select the proper set, we bring in a concept of **regularization**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization\n",
    "When training a model with a certain training set, various sets of parameters can minimize the loss function.\n",
    "\n",
    "![image.png](https://miro.medium.com/max/1200/1*_7OPgojau8hkiPUiHoGK_w.png)\n",
    "\n",
    "This is because the model focuses on only fitting the training dataset. The more complex the model is, the more accurate it seems to become.\n",
    "\n",
    "However, the final objective of the model is to accurately classify new data in, say, a test dataset. A model that focuses on fitting all data in the training set tend to become too complex and **overfit** that dataset, decreasing its performance in predicting new data. According to **Occam's Razor**, the simple model is better.\n",
    "\n",
    "**Regularization** is a method for penalizing complexity of a model.\n",
    "\n",
    "$$L = {1 \\over N} {\\sum_i}L_i(f(x_i, W, b), y_i) + \\lambda \\cdot R(w)$$\n",
    "\n",
    "- $\\lambda$ is the regularization strength. It is a hyperparameter that regulates the tradeoff between *data loss* and *regularization loss*\n",
    "- $R(w)$ is the regularization loss function, which takes the parameter sest $W$ and measures its complexity\n",
    "\n",
    "There are several regularization methods commonly used.\n",
    "\n",
    "- **L2 Regularization** : $R(w) = \\sum_k \\sum_l W_{k \\cdot l}^2$\n",
    "\n",
    "L2 spreads weights along $W$, such as $W = [0.25, 0.25, 0.25, 0.25]$\n",
    "\n",
    "- **L1 Regularization** : $R(w) = \\sum_k \\sum_l \\|W_{k \\cdot l}\\|$\n",
    "\n",
    "L1 prefers sparse weights, such $W= [1, 0, 0, 0]$\n",
    "- Elastic Net (L1 + L2) Regularization : $R(w) = \\sum_k \\sum_l (\\beta \\cdot W_{k \\cdot l}^2 + \\|W_{k \\cdot l}\\|)$\n",
    "\n",
    "\n",
    "- Max Norm Regularization\n",
    "\n",
    "\n",
    "- Dropout Regularization\n",
    "\n",
    "\n",
    "- Batch Regularization\n",
    "\n",
    "\n",
    "- Stochastic depth Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-entropy Loss (Softmax classifier for multinomial logistic regression)\n",
    "Unlike hinge loss, **cross-entropy loss** provides interpretation for scores.\n",
    "\n",
    "\n",
    "$$L_i = -\\log P(Y=y_i | X = x_i)$$\n",
    "$$= - \\log(\\frac{e^s y_i}{\\sum_j e^s j})$$\n",
    "\n",
    "- $\\frac{e^s y_i}{\\sum_j e^s j}$ is a softmax function\n",
    "- $\\sum_j e^s j$ is for normalization\n",
    "- $0 \\leq L_i \\leq \\infty$, but each extreme is impractical in real life\n",
    "\n",
    "#### Some observations\n",
    "1. The model tries to create a probability distribution that matches the target probability distribution\n",
    "2. If the data changes a bit, the model will try to push the probabilty distribution of scores towards the correct class\n",
    "\n",
    "## Final flow of information\n",
    "\n",
    "![image.png](http://cs231n.github.io/assets/dataflow.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Optimization\n",
    "**Optimization** is about finding the best parameter set $W$ using iterative methods. We wish to find values for weights that minimize the loss function.\n",
    "\n",
    "We can use **random search** in which we randomly select weights and hope for the best, but, obviously, it doesn't perform well.\n",
    "\n",
    "A better method would be to start at a random point, and change weights so that the total loss decreases. In other words, we can iteratively move in the direction of steepest descent until we converge and arrive at the minima.\n",
    "\n",
    "![image.png](http://mblogthumb2.phinf.naver.net/20160610_221/tlaja_1465551797371IfR7v_GIF/11.gif?type=w2)\n",
    "\n",
    "This requires computation of the **gradient**($\\nabla_W L$), the vector of partial derivatives along each dimension of the data.\n",
    "\n",
    "### Computing Gradient\n",
    "#### Numerical Gradient\n",
    "We can numerically use the finite difference method to compute the gradient.\n",
    "\n",
    "$$compute \\lim_{h \\rightarrow \\infty} \\frac{L(w+h) - L(w)}{h}\\ for\\ all\\ w \\in W$$\n",
    "\n",
    "This method is **easy to apply** to small $W$'s. However, when the number of weights increase, the numerical method becomes very **slow** and almost impractical to repeatedly use. Therefore, we use this method in only **debugging**, to test whether the gradient is computed accurately. In actual appliance, we use a more analytic method.\n",
    "\n",
    "\n",
    "#### Analytic Gradient\n",
    "Because loss is a function of $W$, we can simply use the loss function to compute the gradient of $W$.\n",
    "\n",
    "$$compute \\nabla_W L$$\n",
    "\n",
    "This method is much **faster** and **exact**.\n",
    "\n",
    "### Conclusion\n",
    "Derive analytic gradient and then check your implementation with numerical gradient.\n",
    "\n",
    "### Gradient Descent\n",
    "**Gradient descent** is an algorithm that explains how to optimize $W$ using the gradient of the loss function computed above. This is an iterative method in which we repeatedly evaluate the gradient and then perform a parameter update.\n",
    "\n",
    "1. Randomly initialize $W$\n",
    "2. Compute the loss & gradient\n",
    "3. Update weights ($weights\\ +=\\ -stepsize * weights$)\n",
    "    - $stepsize$ is a hyperparameter also known as the **learning rate**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
